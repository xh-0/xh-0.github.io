---
title: Kafka
icon: /logo/kafka.svg
createTime: 2024/09/25 18:14:09
permalink: /interview/5kl352fe/
---
::: tip 提问
1. 是否有遇到过重复消费的问题? 怎么解决的?
2. 知道流量控制是如何实现的吗?
:::

## 重复消费
### 导致问题的原因
消费重复的本质原因是 offset 值的丢失, 主要有以下两个场景:
1. **宕机**

   Customer 和 Broker 之间 5 秒才同步一次 offset. 如果出现宕机的清空可能导致 offset 没有及时提交, 那 5 秒之间的丢失了.

2. **再均衡机制**

   如果 Customer 在 5 分钟内没有处理完一批消息, 就会触发服务端 partition 再均衡(Rebalance)机制, 导致 offset 提交失败.

### 解决方案
1. 提高消费性能避免触发 Rebalance. 可以使用多线程并发, 调整超时时间还有减少每次从 Broker 上拉取的条数来做到.
2. 使用 `ConsumerRebalanceListener` 监听, 然后在再均衡前后做收尾工作.
3. 使用消息幂等性.
   1. 开启 Kafka 幂等性功能.
   2. 及那个消息生成 md5 存入 Redis, 在每次消费前先检查是否消费过.
